name: SRU Crawler & HuggingFace Upload

on:
  schedule:
    - cron: '0 1 * * 0'  # Every Sunday at 01:00 UTC (customize if needed)
  workflow_dispatch:

jobs:
  crawl-and-upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'  # Or 3.8+ as required

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set Hugging Face token
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: echo "HF_TOKEN is set"

      - name: Run crawler
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python crawler.py

      - name: List output files (for debugging)
        run: ls -lh

      - name: Upload state & results artifact (optional, for backup/resume/debugging)
        uses: actions/upload-artifact@v4
        with:
          name: crawler-state-and-jsonl
          path: |
            output.jsonl
            crawler_state.json
            data_shard_*.jsonl
